{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Overview\n",
        "\n",
        "\n",
        "* This notebook was originally intended to run in colab [link here](https://colab.research.google.com/drive/1miy7mCbC_ZxoyrcgqJj9mc0x4fJdXkWn?usp=sharing)\n",
        "* For versioning across milestones, check our [github](https://github.com/dyeramosu/AC215_snapnutrition)\n",
        "*   FOODD is a large food dataset with several papers on food to calorie/nutrition info mapping. These papers differred from Nutrition5k in that it attempted to identify the food or foods in each image, then map that identification to a known nutrition label for that food type. Nutrition5k did not focus on identifying the food types but does have ingredient lists in its metadata.\n",
        "*   This experimental notebook contains basic EDA, preprocessing ideas, as well as ideation on how to annotate the data for versioning.\n",
        "* This notebook also contains some cells to link colab to our GCP drive, which was successfully then implemented in Nutrition5k_EDA_Base_Model.ipynb\n",
        "\n"
      ],
      "metadata": {
        "id": "m6aZGtteeaPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Drive\n",
        "\n",
        "Choose either the Google Drive or our team GCS bucket"
      ],
      "metadata": {
        "id": "hLvh9iJqitak"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "427j6sNJicqX",
        "outputId": "c8c55502-a178-4fcb-a9bf-139e9ca4da80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Foor Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For GCP Bucket\n",
        "\n",
        "# Authenticate\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Install Cloud Storage FUSE.\n",
        "!echo \"deb https://packages.cloud.google.com/apt gcsfuse-`lsb_release -c -s` main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "!apt -qq update && apt -qq install gcsfuse\n",
        "\n",
        "# Mount a Cloud Storage bucket or location, without the gs:// prefix.\n",
        "mount_path = \"snapnutrition_data_bucket\"  # or a location like \"my-bucket/path/to/mount\"\n",
        "local_path = f\"/mnt/gs/{mount_path}\"\n",
        "\n",
        "!mkdir -p {local_path}\n",
        "!gcsfuse --implicit-dirs {mount_path} {local_path}\n",
        "print('\\n==== GCS Bucket Successfully Mounted ====\\n')\n",
        "!ls -lh {local_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCTitv7hR-bF",
        "outputId": "f396b9b0-a0b3-48a9-f431-4fb447713302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deb https://packages.cloud.google.com/apt gcsfuse-jammy main\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "100  2659  100  2659    0     0  17281      0 --:--:-- --:--:-- --:--:-- 17379\n",
            "OK\n",
            "19 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mhttps://packages.cloud.google.com/apt/dists/gcsfuse-jammy/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\n",
            "gcsfuse is already the newest version (1.1.0).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "I0925 21:56:52.148918 2023/09/25 21:56:52.148871 Start gcsfuse/1.1.0 (Go version go1.20.5) for app \"\" using mount point: /mnt/gs/snapnutrition_data_bucket\n",
            "\n",
            "====GCS Bucket Successfully Mounted====\n",
            "\n",
            "total 0\n",
            "drwxr-xr-x 1 root root 0 Sep 25 21:56 processed_data\n",
            "drwxr-xr-x 1 root root 0 Sep 25 21:56 raw_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA\n",
        "\n",
        "Import Libraries"
      ],
      "metadata": {
        "id": "cg0dOptXi5fY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import glob\n",
        "import pandas as pd\n",
        "import spacy\n"
      ],
      "metadata": {
        "id": "N5tUw70ji8dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we'll need to create a label for each image. The default directory structure is:\n",
        "\n",
        "```\n",
        "<parent>/\n",
        "|----FooDD/\n",
        "     |----<food label>/\n",
        "          |----<camera & lighting>/\n",
        "               |----<image number>.jpg\n",
        "```\n",
        "\n",
        "For now, we won't worry about camera and lighting information. Instead, We'll create a json file that annotates each food label with paths to all corresponding images. It will be structured:\n",
        "\n",
        "```\n",
        "{\n",
        "    \"<food label 1>\":[\n",
        "        <image path 1>,\n",
        "        <image path 2>,\n",
        "        <image path N>\n",
        "    ],\n",
        "    \"<food label 2>\":[\n",
        "        <image path 1>,\n",
        "        <image path 2>,\n",
        "        <image path N>\n",
        "    ]\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "i2EK-LyMkRlg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose the cell below based upon which drive is mounted"
      ],
      "metadata": {
        "id": "9P-tDUZSU1Uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For Google Drive\n",
        "root = '/content/drive/MyDrive/AC215'\n",
        "\n",
        "# Set FooDD folder\n",
        "FooDD = 'data/FooDD'"
      ],
      "metadata": {
        "id": "M7AZiTnTMa8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For GCP Bucket\n",
        "root = local_path\n",
        "\n",
        "# Set FooDD folder\n",
        "FooDD = 'raw_data/FooDD'"
      ],
      "metadata": {
        "id": "GJT0-FnQVPRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll create an annotations dictionary and see what food categories are in the dataset."
      ],
      "metadata": {
        "id": "ZAUcKtTKVF30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty annotations dictionary\n",
        "annotations = dict()\n",
        "\n",
        "# Iterate through directory\n",
        "for food in os.listdir(os.path.join(root, FooDD)):\n",
        "    food_path = os.path.join(FooDD, food)\n",
        "\n",
        "    # Note: the creators of this dataset included images they found from the\n",
        "    # web. We'll set them aside for now\n",
        "    if (food == \"Net images\" or not os.path.isdir(os.path.join(root, food_path))):\n",
        "        continue\n",
        "\n",
        "    food = food.lower().replace(' ','_')\n",
        "    print(food)\n",
        "\n",
        "    image_paths = glob.glob(\n",
        "        \"**/*.[Jj][Pp][Gg]\",\n",
        "        root_dir=os.path.join(root, food_path),\n",
        "        recursive=True\n",
        "    )\n",
        "\n",
        "    annotations[food] = []\n",
        "    for image_path in image_paths:\n",
        "        annotations[food].append(os.path.join(food_path, image_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kq-CVLincY2s",
        "outputId": "ff011f35-c941-403c-afda-4d2139fc52b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apple\n",
            "banana\n",
            "bean\n",
            "bread\n",
            "carrot\n",
            "cheese\n",
            "cucumber\n",
            "egg\n",
            "grape\n",
            "grape_&_apple\n",
            "mixed\n",
            "onion\n",
            "orange\n",
            "pasta\n",
            "pepper\n",
            "qiwi\n",
            "tomato\n",
            "watermelon\n",
            "sauce\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to clean up the labels a bit before proceeding. `grape_&_apple` is technically `mixed`, so we'll change the label. We'll also rename `qiwi` to the more common `kiwi`"
      ],
      "metadata": {
        "id": "6j_b09STjlOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge grape_&_apple into mixed\n",
        "annotations['mixed'].extend(annotations['grape_&_apple'])\n",
        "del annotations['grape_&_apple']\n",
        "\n",
        "# Rename qiwi to kiwi\n",
        "annotations['kiwi'] = annotations.pop('qiwi')"
      ],
      "metadata": {
        "id": "8e1S4K6ulRkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print results\n",
        "for key in annotations.keys():\n",
        "    print(key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gfu9kRcbj8XN",
        "outputId": "fa25eddb-62fa-4ab8-98d6-0947d8300990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apple\n",
            "banana\n",
            "bean\n",
            "bread\n",
            "carrot\n",
            "cheese\n",
            "cucumber\n",
            "egg\n",
            "grape\n",
            "mixed\n",
            "onion\n",
            "orange\n",
            "pasta\n",
            "pepper\n",
            "tomato\n",
            "watermelon\n",
            "sauce\n",
            "kiwi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's take a look at the \"Net images\" file to see what types of food are there. We'll need to get the names of each file and remove any capitalization, numbers, characters, and plural forms to standardize.  "
      ],
      "metadata": {
        "id": "Ro4kEXs50nXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use spaCy to process file names\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Create a consolidated dictionary with food type as the key\n",
        "net_images = dict()\n",
        "\n",
        "for file_name in os.listdir(os.path.join(root, FooDD, \"Net images\")):\n",
        "\n",
        "    # Remove extension, spaces, numbers, and special characters\n",
        "    food = nlp(os.path.splitext(file_name)[0])\n",
        "    food = '_'.join([token.lemma_.lower() for token in food if token.is_alpha])\n",
        "\n",
        "    path = os.path.join(FooDD, \"Net images\", file_name)\n",
        "    if food in net_images:\n",
        "        net_images[food].append(path)\n",
        "    else:\n",
        "        net_images[food] = [path]"
      ],
      "metadata": {
        "id": "Z4C1rChPuklz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the resulting foods\n",
        "print(f'Additional foods from \"Net images\" folder: {len(net_images)}')\n",
        "for food in net_images.keys():\n",
        "    print(food)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb5-3-Li2G1g",
        "outputId": "0889a2e6-a2d0-4d81-88dc-880d18a30255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Additional foods from \"Net images\" folder: 60\n",
            "cucumber\n",
            "friedchicken\n",
            "\n",
            "apple\n",
            "apricot\n",
            "aubergine\n",
            "avocado\n",
            "beetroot\n",
            "bread\n",
            "cabbage\n",
            "carrot\n",
            "cauliflower\n",
            "cherry\n",
            "chili\n",
            "coconut\n",
            "corn\n",
            "date\n",
            "egg\n",
            "fig\n",
            "garlic\n",
            "ginger\n",
            "grapefruit\n",
            "grape\n",
            "green_onion\n",
            "green_pepper\n",
            "guava\n",
            "imagescavutofk\n",
            "kiwi\n",
            "lemon\n",
            "lemone\n",
            "lentil\n",
            "lettuce\n",
            "mandarin\n",
            "mango\n",
            "melon\n",
            "mushroom\n",
            "okra\n",
            "olive\n",
            "onion\n",
            "orang\n",
            "orange\n",
            "papaya\n",
            "peach\n",
            "pear\n",
            "pineapple\n",
            "pomegranate\n",
            "potato\n",
            "radish\n",
            "raspberry\n",
            "red_pepper\n",
            "red_radish\n",
            "rice\n",
            "spinach\n",
            "strawberry\n",
            "sweet_potato\n",
            "tomato\n",
            "untitled\n",
            "watermelon\n",
            "white_radish\n",
            "zucchini\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to clean a few things up with the labels in this folder:\n",
        "- Merge `untitled` and `imagescavutofk` to grape\n",
        "- Rename `<blank>` to mixed\n",
        "- Merge `lemone` and `lemon`\n",
        "- Rename `aubergine` to `eggplant`\n",
        "- Rename `beetroot` to `beet`\n",
        "- Rename `friedchicken` to `fried_chicken`\n",
        "- Merge `orang` and `orange`\n",
        "- Move `imagesCAKOFJ21.jpg` to watermelon"
      ],
      "metadata": {
        "id": "r8Lm3A4CophH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge untitled into grape\n",
        "net_images['grape'].extend(net_images['untitled'])\n",
        "del net_images['untitled']\n",
        "\n",
        "# Merge imagescavutofk into grape\n",
        "net_images['grape'].extend(net_images['imagescavutofk'])\n",
        "del net_images['imagescavutofk']\n",
        "\n",
        "# Rename <blank> to mixed\n",
        "net_images['mixed'] = net_images.pop('')\n",
        "\n",
        "# Merge lemone into lemon\n",
        "net_images['lemon'].extend(net_images['lemone'])\n",
        "del net_images['lemone']\n",
        "\n",
        "# Rename aubergine to eggplant\n",
        "net_images['eggplant'] = net_images.pop('aubergine')\n",
        "\n",
        "# Rename beetroot to beet\n",
        "net_images['beet'] = net_images.pop('beetroot')\n",
        "\n",
        "# Rename friedchicken to fried_chicken\n",
        "net_images['fried_chicken'] = net_images.pop('friedchicken')\n",
        "\n",
        "# Merge orang into orange\n",
        "net_images['orange'].extend(net_images['orang'])\n",
        "del net_images['orang']\n",
        "\n",
        "# Move imagesCAKOFJ21.jpg to watermelon\n",
        "net_images['watermelon'].append(os.path.join(FooDD, \"Net images\", \"imagesCAKOFJ21.jpg\"))\n",
        "net_images['mixed'].remove(os.path.join(FooDD, \"Net images\", \"imagesCAKOFJ21.jpg\"))"
      ],
      "metadata": {
        "id": "5stXyycxpQXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we'll merge `net_images` with `annotations` in preperation for creating our JSON file."
      ],
      "metadata": {
        "id": "V5BbYqAQZ59D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge net_images with annotations\n",
        "for food in net_images.keys():\n",
        "    if food in annotations:\n",
        "        annotations[food].extend(net_images[food])\n",
        "    else:\n",
        "        annotations[food] = net_images[food]\n"
      ],
      "metadata": {
        "id": "3gLYYko079oP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose the cell below based upon which drive is mounted. This will create an `annotations.json` file in the format discussed earlier"
      ],
      "metadata": {
        "id": "iav-CTjZfe53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For Google Drive\n",
        "\n",
        "# Specify the name of the JSON file\n",
        "file_name = 'annotations.json'\n",
        "\n",
        "# Open the file in write mode and save the dictionary as JSON\n",
        "with open(os.path.join(root, FooDD, file_name), 'w') as json_file:\n",
        "    json.dump(annotations, json_file)"
      ],
      "metadata": {
        "id": "9PfvwN0GLjnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For GCP Bucket\n",
        "from google.cloud import storage\n",
        "\n",
        "# Specify the name of the JSON file\n",
        "file_name = 'annotations.json'\n",
        "\n",
        "\n",
        "storage_client = storage.Client()\n",
        "bucket = storage_client.bucket(mount_path)\n",
        "blob = bucket.blob(os.path.join(FooDD, file_name))\n",
        "\n",
        "\n",
        "# Open the file in write mode and save the dictionary as JSON\n",
        "with blob.open('w') as json_file:\n",
        "    json.dump(annotations, json_file)"
      ],
      "metadata": {
        "id": "8SuCKKh0gL2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start the notebook here after `annotations.json` is created. Choose the cell based upon which drive is mounted."
      ],
      "metadata": {
        "id": "QHSijBRnOaDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For Google Drive\n",
        "with open(os.path.join(root, FooDD, 'annotations.json'), 'r') as json_file:\n",
        "    # Load the JSON data into a Python dictionary\n",
        "    annotations = json.load(json_file)"
      ],
      "metadata": {
        "id": "WPd5PAwzwdJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For GCP Bucket\n",
        "# from google.cloud import storage\n",
        "\n",
        "# storage_client = storage.Client()\n",
        "# bucket = storage_client.bucket(mount_path)\n",
        "# blob = bucket.blob(os.path.join(FooDD, 'annotations.json'))\n",
        "\n",
        "# with blob.open(\"r\") as json_file:\n",
        "#     # Load the JSON data into a Python dictionary\n",
        "#     annotations = json.load(json_file)\n"
      ],
      "metadata": {
        "id": "8VMD_y9HjnSW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have a look at some of the contents in this dataset."
      ],
      "metadata": {
        "id": "oSNo4P0ljYjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of food classes: {len(annotations)}')\n",
        "print(f'Number of images: {sum(len(value) for value in annotations.values())}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLR24CQdwpiM",
        "outputId": "2aabfb32-b455-4a3e-92fb-26afbb8e9582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of food classes: 62\n",
            "Number of images: 3886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "for food, paths in annotations.items():\n",
        "    labels.extend([food]*len(paths))\n",
        "df = pd.DataFrame({'label':labels})\n",
        "print('Number of images for each food class:\\n')\n",
        "food_counts = df['label'].value_counts()\n",
        "pd.set_option('display.max_rows', len(food_counts))\n",
        "print(food_counts)\n",
        "pd.reset_option('display.max_rows')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObXQBCTTC4cj",
        "outputId": "9aff2cea-a65a-457d-e316-8026d039938a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images for each food class:\n",
            "\n",
            "apple            453\n",
            "onion            339\n",
            "bean             279\n",
            "tomato           277\n",
            "bread            270\n",
            "egg              269\n",
            "cheese           259\n",
            "orange           241\n",
            "sauce            210\n",
            "pasta            207\n",
            "grape            167\n",
            "mixed            144\n",
            "cucumber         123\n",
            "banana           119\n",
            "carrot            98\n",
            "pepper            94\n",
            "watermelon        78\n",
            "kiwi              68\n",
            "grapefruit        15\n",
            "lemon             12\n",
            "pomegranate       11\n",
            "cabbage           11\n",
            "papaya             9\n",
            "apricot            8\n",
            "avocado            8\n",
            "zucchini           7\n",
            "eggplant           6\n",
            "melon              6\n",
            "coconut            5\n",
            "olive              5\n",
            "chili              5\n",
            "strawberry         5\n",
            "garlic             5\n",
            "sweet_potato       5\n",
            "pineapple          5\n",
            "pear               4\n",
            "mango              3\n",
            "guava              3\n",
            "date               3\n",
            "lettuce            3\n",
            "cherry             3\n",
            "raspberry          3\n",
            "peach              3\n",
            "red_radish         3\n",
            "corn               3\n",
            "mushroom           3\n",
            "cauliflower        3\n",
            "ginger             3\n",
            "green_onion        3\n",
            "spinach            3\n",
            "okra               2\n",
            "lentil             2\n",
            "beet               2\n",
            "fig                2\n",
            "white_radish       2\n",
            "radish             1\n",
            "red_pepper         1\n",
            "rice               1\n",
            "green_pepper       1\n",
            "potato             1\n",
            "mandarin           1\n",
            "fried_chicken      1\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2pWR4s9aNcOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Potentially useful methods:"
      ],
      "metadata": {
        "id": "8usoShjhL5xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# step 1\n",
        "filenames = tf.constant(list(df_all_meta['image_id']))\n",
        "labels = tf.constant(list(df_all_meta['label']))\n",
        "\n",
        "# step 2: create a dataset returning slices of `filenames`\n",
        "dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
        "\n",
        "# step 3: parse every image in the dataset using `map`\n",
        "def _parse_function(filename, label):\n",
        "    image_string = tf.io.read_file('drive_path_to_image' + filename)\n",
        "    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
        "    image = tf.cast(image_decoded, tf.float32)/255\n",
        "    return image, label\n",
        "\n",
        "dataset = dataset.map(_parse_function)"
      ],
      "metadata": {
        "id": "FQMRymknyRJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "D3SHlEETSICc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Method that takes images and converts them to a uniform size.\n",
        "\n",
        "def resize_images(images, target_size):\n",
        "    resized_images = tf.image.resize(images, target_size)\n",
        "    return resized_images\n",
        "\n",
        "# In the above code, `images` is the input tensor containing a batch of images,\n",
        "# and `target_size` is the desired size for the images, specified as a tuple `(height, width)`.\n",
        "# The `resize_images` function uses `tf.image.resize` to resize each image in the batch to the target size."
      ],
      "metadata": {
        "id": "3x5h_PRTSI52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Archived Cells"
      ],
      "metadata": {
        "id": "yfv1WSaejcQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Create an empty annotations dictionary\n",
        "# annotations = dict()\n",
        "\n",
        "# # Iterate through directory\n",
        "# for i, food in enumerate(os.listdir(path)):\n",
        "#     food_path = os.path.join(path, food)\n",
        "\n",
        "#     # Note: the creators of this dataset included images they found from the\n",
        "#     # web. We'll set them aside for now\n",
        "#     if (food == \"Net images\" or not os.path.isdir(os.path.join(path, food))):\n",
        "#         continue\n",
        "\n",
        "#     food = food.lower().replace(' ','_')\n",
        "#     print(food)\n",
        "#     images = glob.glob(\"**/*.[Jj][Pp][Gg]\", root_dir=food_path, recursive=True)\n",
        "\n",
        "#     for j, image_path in enumerate(images):\n",
        "#         image_id = str(i).zfill(3) + str(j).zfill(5)\n",
        "#         image_path = os.path.join(food_path, image_path)\n",
        "#         image= cv2.imread(image_path)\n",
        "#         height, width = image.shape[:2]\n",
        "#         annotations[image_id] = {\n",
        "#             'path': image_path,\n",
        "#             'label': food,\n",
        "#             'width': width,\n",
        "#             'height': height\n",
        "#         }\n",
        "\n",
        "# # Could also make the annotations file simply keyed off the label and a list of\n",
        "# #  values that are just the path to the image. No unique ID needed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNt3OgS6g7ry",
        "outputId": "95549239-6502-450f-9a6b-b746515ad6c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apple\n",
            "cucumber\n",
            "bread\n",
            "carrot\n",
            "bean\n",
            "banana\n",
            "cheese\n",
            "mixed\n",
            "onion\n",
            "orange\n",
            "grape\n",
            "egg\n",
            "grape_&_apple\n",
            "tomato\n",
            "pepper\n",
            "qiwi\n",
            "pasta\n",
            "sauce\n",
            "watermelon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# labels, heights, widths = [], [], []\n",
        "\n",
        "# for k, v in annotations.items():\n",
        "#     labels.append(v['label'])\n",
        "#     heights.append(v['height'])\n",
        "#     widths.append(v['width'])"
      ],
      "metadata": {
        "id": "qeLcniY7wz9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f'Number of foods: {len(set(labels))}')\n",
        "# print(f'Number of unique image sizes: {len(set(zip(widths, heights)))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGkc-V78xilf",
        "outputId": "c9e4f234-2817-464d-9f5b-b4b6453627a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of foods: 19\n",
            "Number of unique image sizes: 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "digits = 7\n",
        "print(f'{time.time():.{digits}f}')\n",
        "print(time.time())\n",
        "print(time.time())\n",
        "print(time.time())\n",
        "print(time.time())\n",
        "print(time.time())"
      ],
      "metadata": {
        "id": "swx_EIInSNhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "754224d2-3010-4283-b524-633a7e6f3215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1695590215.7572193\n",
            "1695590215.759003\n",
            "1695590215.7595582\n",
            "1695590215.7600505\n",
            "1695590215.760544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str(time.time()).replace('.','')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "U2oaFXTqD5Bu",
        "outputId": "4cee150b-e325-4a91-a950-b0e5eae3fd38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1695590901707672'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "\n",
        "print(uuid.uuid4())\n",
        "print(uuid.uuid4())\n",
        "print(uuid.uuid4())\n",
        "print(uuid.uuid4())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qa5Rut99BYJd",
        "outputId": "cb798036-5856-479b-e6df-b5f0c0020e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "955feba2-bf66-46e4-95b6-789ba18223d9\n",
            "6a180f83-c1e0-462c-92ee-c661d3c23118\n",
            "126e3de0-fd17-4c2d-91e3-94ff36248488\n",
            "bf0ff9eb-71d6-46a3-92b1-205c59be2895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(uuid.uuid1())\n",
        "print(uuid.uuid1())\n",
        "print(uuid.uuid1())\n",
        "print(uuid.uuid1())\n",
        "print(uuid.uuid1())\n",
        "print(uuid.uuid1())\n",
        "print(uuid.uuid1())\n",
        "print(uuid.uuid1())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSj28jBtBtb-",
        "outputId": "e644ccb3-581e-43b3-c55f-680aa18666ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2ea01ac0-5b1f-11ee-a5c4-0242ac1c000c\n",
            "2ea063a4-5b1f-11ee-a5c4-0242ac1c000c\n",
            "2ea07ca4-5b1f-11ee-a5c4-0242ac1c000c\n",
            "2ea091c6-5b1f-11ee-a5c4-0242ac1c000c\n",
            "2ea0a68e-5b1f-11ee-a5c4-0242ac1c000c\n",
            "2ea0b3ae-5b1f-11ee-a5c4-0242ac1c000c\n",
            "2ea0b7be-5b1f-11ee-a5c4-0242ac1c000c\n",
            "2ea0bb6a-5b1f-11ee-a5c4-0242ac1c000c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str(uuid.uuid4())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zxkEoXi_CaRF",
        "outputId": "4527be25-d861-425f-cb6e-afbf3fdbe0a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'36a9f877-99ea-4fbe-94a0-cdd09aa66194'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of trying to version the raw data GCP bucket, just version the processed data bucket. So we'll come up with a unique annotations.json file for each dataset we add to the raw bucket that always has the same format. This will be done once in a colab notebook and then uploaded to the GCP bucket. The annotations file will have the food category as the key, and the value will be a list of strings that point to the file path of each image. Perhaps might also include the citation of the source of the data.\n",
        "\n",
        "The preprocessing container will look for this annotations.json to perform all of the pipeline transformations, and then store the processed images into another GCP bucket. The processed images will need a unique ID, so we'll use the UUID package to assign something unique for each image. It might also be smart to create another json file in this processed data bucket that points from the UUID to the original file path, labels, and source of the data.\n",
        "\n",
        "The version containter will keep track of only the processed data bucket."
      ],
      "metadata": {
        "id": "F3yjhNr5HsaU"
      }
    }
  ]
}